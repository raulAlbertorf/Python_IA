{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"},"colab":{"name":"hashtagsummarizer.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"DM_qjFNj1wGH","colab_type":"text"},"source":["Import this app's dependencies."]},{"cell_type":"code","metadata":{"id":"3mM2T8EG1wGK","colab_type":"code","colab":{}},"source":["from pyspark import SparkContext\n","from pyspark.streaming import StreamingContext\n","from pyspark.sql import Row, SparkSession\n","from IPython import display\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qkFQzzCr1wGe","colab_type":"text"},"source":["From the PySpark Streaming Programming Guide at https://spark.apache.org/docs/latest/streaming-programming-guide.html#dataframe-and-sql-operations. This is the recommended way for each cluster node to get the SparkSession."]},{"cell_type":"code","metadata":{"id":"st_oU4jN1wGi","colab_type":"code","colab":{}},"source":["def getSparkSessionInstance(sparkConf):\n","    \"\"\"Spark Streaming Programming Guide's recommended method \n","       for getting an existing SparkSession or creating a new one.\"\"\"\n","    if (\"sparkSessionSingletonInstance\" not in globals()):\n","        globals()[\"sparkSessionSingletonInstance\"] = SparkSession \\\n","            .builder \\\n","            .config(conf=sparkConf) \\\n","            .getOrCreate()\n","    return globals()[\"sparkSessionSingletonInstance\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qaPQeoj-1wG9","colab_type":"text"},"source":["Function to display a Seaborn barplot based on the Spark DataFrame it receives. "]},{"cell_type":"code","metadata":{"id":"0sW7XrCY1wHH","colab_type":"code","colab":{}},"source":["def display_barplot(spark_df, x, y, time, scale=2.0, size=(16, 9)):\n","    \"\"\"Displays a Spark DataFrame's contents as a bar plot.\"\"\"\n","    df = spark_df.toPandas()\n","    \n","    # remove prior graph when new one is ready to display\n","    display.clear_output(wait=True) \n","    print(f'TIME: {time}')\n","    \n","    # create and configure a Figure containing a Seaborn barplot \n","    plt.figure(figsize=size)\n","    sns.set(font_scale=scale)\n","    barplot = sns.barplot(data=df, x=x, y=y, \n","                          palette=sns.color_palette('cool', 20))\n","    \n","    # rotate the x-axis labels 90 degrees for readability\n","    for item in barplot.get_xticklabels():\n","        item.set_rotation(90)\n","        \n","    plt.tight_layout()\n","    plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_xfLlJvY1wHR","colab_type":"text"},"source":["Function count_tags is called for every RDD to summarize the hashtag counts in that RDD, add them to the existing totals, then display an updated top-20 barplot."]},{"cell_type":"code","metadata":{"id":"EvDWmtBN1wHS","colab_type":"code","colab":{}},"source":["def count_tags(time, rdd):\n","    \"\"\"Count hashtags and display top-20 in descending order.\"\"\"\n","    try:\n","        # get SparkSession\n","        spark = getSparkSessionInstance(rdd.context.getConf()) \n","        \n","        # map hashtag string-count tuples to Rows \n","        rows = rdd.map(\n","            lambda tag: Row(hashtag=tag[0], total=tag[1])) \n","        \n","        # create a DataFrame from the Row objects\n","        hashtags_df = spark.createDataFrame(rows)\n","\n","        # create a temporary table view for use with Spark SQL\n","        hashtags_df.createOrReplaceTempView('hashtags')\n","        \n","        # use Spark SQL to get the top 20 hashtags in descending order\n","        top20_df = spark.sql(\n","            \"\"\"select hashtag, total \n","               from hashtags \n","               order by total desc, hashtag asc \n","               limit 20\"\"\")\n","        display_barplot(top20_df, x='hashtag', y='total', time=time)\n","    except Exception as e:\n","        print(f'Exception: {e}')\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ef1AAGLw1wHm","colab_type":"text"},"source":["Main applications code sets up Spark streaming to read text from the `starttweetstream.py` script on localhost port 9876 and specifies how to process the tweets."]},{"cell_type":"code","metadata":{"id":"ypJ2H7fp1wHn","colab_type":"code","colab":{}},"source":["sc = SparkContext()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ism4aViD1wHs","colab_type":"code","colab":{}},"source":["ssc = StreamingContext(sc, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"izBC8IaA1wHw","colab_type":"code","colab":{}},"source":["ssc.checkpoint('hashtagsummarizer_checkpoint')  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MGg29YU71wHz","colab_type":"code","colab":{}},"source":["stream = ssc.socketTextStream('localhost', 9876)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vqxfok51wH3","colab_type":"code","colab":{}},"source":["tokenized = stream.flatMap(lambda line: line.split())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XLUhgI8H1wH7","colab_type":"code","colab":{}},"source":["mapped = tokenized.map(lambda hashtag: (hashtag, 1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iv7DDqHW1wH9","colab_type":"code","colab":{}},"source":["hashtag_counts = mapped.updateStateByKey(\n","    lambda counts, prior_total: sum(counts) + (prior_total or 0)) "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kd9PCrjj1wIU","colab_type":"code","colab":{}},"source":["hashtag_counts.foreachRDD(count_tags)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yf85X3N91wIX","colab_type":"code","colab":{}},"source":["ssc.start()  # start the Spark streaming"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lP-JkBC01wIa","colab_type":"code","colab":{}},"source":["#ssc.awaitTermination()  # wait for the streaming to finish"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mhVkPWgB1wIc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}